{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_MNIST.py",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saeeeae/Pytorch-Studying/blob/master/GAN_MNIST_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8uCKT5mUBpx",
        "colab_type": "code",
        "outputId": "e7b59f8b-1538-457a-9e2f-2eb82f6c2527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "# \"gdrive/My Drive/Colab Notebooks/faces/face_landmarks.csv\"\n",
        "\n",
        "# data 전처리 방식 지정\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),  # data를 pytorch Tensor 형식으로 변형\n",
        "                                transforms.Normalize(mean=(0.5,), std=(0.5,)) # 픽셀값 0 ~ 1 -> -1 ~ 1\n",
        "])\n",
        "\n",
        "mnist = datasets.MNIST(root='gdrive/My Drive/Colab Notebooks/data', download=True, transform=transform)\n",
        "\n",
        "dataloader = DataLoader(mnist, batch_size=60, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rE56dvUJxL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import imageio\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "leave_log = True\n",
        "\n",
        "if leave_log:\n",
        "  result_dir = 'gdrive/My Drive/Colab Notebooks/data/GAN_generated_images'\n",
        "  if not os.path.isdir(result_dir):\n",
        "    os.mkdir(result_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUQTVbeGV-KJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### GAN 생성자 (Generator)\n",
        "# 생성자는 랜덤 벡터 z를 입력으로 받아 가짜 이미지 출력함\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "  # 네트워크 구조\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "        nn.Linear(in_features=100, out_features=256),\n",
        "        nn.LeakyReLU(0.2, inplace=False),\n",
        "        nn.Linear(in_features=256, out_features=512),\n",
        "        nn.LeakyReLU(0.2, inplace=False),\n",
        "        nn.Linear(in_features=512, out_features=1024),\n",
        "        nn.LeakyReLU(0.2, inplace=False),\n",
        "        nn.Linear(in_features=1024, out_features=28*28),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "    # batch_size * 100 크기의 랜덤 벡터를 받아\n",
        "    # 이미지를 batch_size * 1 * 28 * 28 크기로 출력함\n",
        "  def forward(self, inputs):\n",
        "    return self.main(inputs).view(-1,1,28,28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7sCXSAXYaLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### GAN 구분자 (Discriminator)\n",
        "# 구분자는 이미지를 입력으로 받아 이미지가 진짜인지 가짜인지 출력\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "        nn.Linear(in_features=28*28, out_features=1024),\n",
        "        nn.LeakyReLU(0.2, inplace=False),\n",
        "        nn.Dropout(inplace=False),\n",
        "        nn.Linear(in_features=1024, out_features=512),\n",
        "        nn.LeakyReLU(0.2, inplace=False),\n",
        "        nn.Dropout(inplace=False),\n",
        "        nn.Linear(in_features=512, out_features=256),\n",
        "        nn.LeakyReLU(0.2, inplace=False),\n",
        "        nn.Dropout(inplace=False),\n",
        "        nn.Linear(in_features=256, out_features=1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  # batch_size * 1 * 28 * 28 크기 이미지를 받아\n",
        "  # 이미지가 진짜일 확률을 0 ~ 1 사이로 출력\n",
        "  def forward(self, inputs):\n",
        "    inputs = inputs.view(-1, 28*28)\n",
        "    return self.main(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J5XAybyqaUTI",
        "colab": {}
      },
      "source": [
        "### 생성자와 구분자 객체 만들기\n",
        "\n",
        "G = Generator()\n",
        "D = Discriminator()\n",
        "\n",
        "if use_gpu:\n",
        "  G.cuda()\n",
        "  D.cuda()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dhQmqOzlaZTu",
        "colab": {}
      },
      "source": [
        "### 손실함수와 최적화 기법 지정\n",
        "# Binary Cross Entropy Loss\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# 생성자 매개변수를 최적화 하는 Adam optimizer\n",
        "G_optimizer = Adam(G.parameters(), lr=0.0002, betas= (0.5, 0.999))\n",
        "# 구분자의 매개변수를 최적화하는 Adam optimizer\n",
        "D_optimizer = Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBJ_egLTdJm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습결과 시각화\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def square_plot(data, path):\n",
        "  if type(data) == list:\n",
        "    data = np.concatenate(data)\n",
        "  # normalize data for display\n",
        "  data = (data - data.min()) / (data.max() - data.min())\n",
        "\n",
        "  # force the number of filters to be square\n",
        "  n = int(np.ceil(np.sqrt(data.shape[0])))\n",
        "  ### ???\n",
        "\n",
        "  padding = (((0, n**2 - data.shape[0]), (0, 1), (0, 1))+ ((0, 0),) * (data.ndim -3))\n",
        "  ## padding 이해해보기 !!!!\n",
        "\n",
        "  data = np.pad(data, padding, mode='constant', constant_values=1)\n",
        "\n",
        "  data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
        "\n",
        "  data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
        "\n",
        "  plt.imsave(path, data, cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MIy1WXUez7z",
        "colab_type": "code",
        "outputId": "a183da0e-4f4f-4c6d-d429-57f3f5a59b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "if leave_log:\n",
        "  train_hist = {}\n",
        "  train_hist['D_losses'] = []\n",
        "  train_hist['G_losses'] = []\n",
        "  generated_images = []\n",
        "\n",
        "z_fixed = Variable(torch.randn(5*5, 100), volatile = True)\n",
        "\n",
        "if use_gpu:\n",
        "  z_fixed = z_fixed.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq_UNUwEhGUq",
        "colab_type": "code",
        "outputId": "d7a50c05-3399-4aa4-f885-7b0ece43ad75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(100):\n",
        "  \n",
        "  if leave_log:\n",
        "    D_losses = []\n",
        "    G_losses = []\n",
        "\n",
        "  # 한번에 batch_size 만큼 데이터를 가져옴\n",
        "  for real_data, _ in dataloader:\n",
        "    batch_size = real_data.size(0)\n",
        "\n",
        "    # 데이터를 pytorch 변수로 변환\n",
        "    real_data = Variable(real_data)\n",
        "\n",
        "    ### 구분자 학습\n",
        "\n",
        "    # 이미지가 진짜일 때 정답 값은 1, 가짜 값은 0\n",
        "    # 정답지에 해당하는 변수를 만듦\n",
        "    target_real = Variable(torch.ones(batch_size, 1))\n",
        "    target_fake = Variable(torch.zeros(batch_size, 1))\n",
        "\n",
        "    if use_gpu:\n",
        "      real_data, target_real, target_fake = real_data.cuda(), target_real.cuda(), target_fake.cuda()\n",
        "\n",
        "    # 진짜 이미지를 구분자에 넣음\n",
        "    D_result_from_real = D(real_data)\n",
        "    # 구분자 출력값이 정답지인 1에서 멀수록 loss가 높아짐\n",
        "    D_loss_real = criterion(D_result_from_real, target_real)\n",
        "\n",
        "    # 생성자에 입력으로 줄 랜덤 벡터 z를 만든다\n",
        "    z = Variable(torch.randn((batch_size, 100)))\n",
        "\n",
        "    if use_gpu:\n",
        "      z = z.cuda()\n",
        "\n",
        "    # 생성자로 가짜 이미지를 생성\n",
        "    fake_data = G(z)\n",
        "\n",
        "    # 생성자가 만든 가짜 이미지를 구분자에 넣음\n",
        "    D_result_from_fake = D(fake_data)\n",
        "    # 구분자 출력값이 정답지인 0에서 멀수록 loss가 높음\n",
        "    D_loss_fake = criterion(D_result_from_fake, target_fake)\n",
        "\n",
        "    # 구분자의 loss는 두 문제에서 계산된 loss의 합\n",
        "    D_loss = D_loss_real + D_loss_fake\n",
        "\n",
        "    # 구분자 매개변수 미분값을 0으로 초기화\n",
        "    D.zero_grad()\n",
        "    # 역전파를 통해 매개변수의 loss에 대한 미분값 계산\n",
        "    D_loss.backward()\n",
        "    # 최적화 기법을 이용해 구분자 매개변수 업데이트\n",
        "    D_optimizer.step()\n",
        "\n",
        "    if leave_log:\n",
        "      D_losses.append(D_loss.item())\n",
        "\n",
        "      # train generator G\n",
        "      ### 생성자 학습시키기\n",
        "\n",
        "      # 생성자에 입력으로 줄 랜덤 벡터 z를 만듦\n",
        "      z = Variable(torch.randn((batch_size, 100)))\n",
        "\n",
        "      if use_gpu:\n",
        "        z = z.cuda()\n",
        "\n",
        "      # 생성자로 가짜 이미지를 생성\n",
        "      fake_data = G(z)\n",
        "      # 생성자가 만든 가짜 이미지를 구분자에 넣음\n",
        "      D_result_from_fake = D(fake_data)\n",
        "      # 생성자의 입장에서 구분자의 출력값이 1에서 멀수록 loss가 높아짐\n",
        "      G_loss = criterion(D_result_from_fake, target_real)\n",
        "\n",
        "      # 생성자의 매개 변수 미분값을 0으로 초기화\n",
        "      G.zero_grad()\n",
        "      # 역전파를 통해 매개변수 loss에 대한 미분값 계산\n",
        "      G_loss.backward()\n",
        "      # 최적화 기법을 통해 생성자 매개변수 업데이트\n",
        "      G_optimizer.step()\n",
        "\n",
        "      if leave_log:\n",
        "        G_losses.append(G_loss.item())\n",
        "    \n",
        "  if leave_log:\n",
        "    true_positive_rate = (D_result_from_real > 0.5).float().mean().data\n",
        "    true_negative_rate = (D_result_from_fake < 0.5).float().mean().data\n",
        "    base_message = (\"Epoch: {epoch:<3d} D Loss: {d_loss:<8.6} G Loss: {g_loss:<8.6} \" \"True Positive Rate: {tpr:<5.1%} True Negative Rate: {tnr:<5.1%}\")\n",
        "\n",
        "    message = base_message.format(\n",
        "        epoch = epoch,\n",
        "        d_loss = sum(D_losses)/len(D_losses),\n",
        "        g_loss = sum(G_losses)/len(G_losses),\n",
        "        tpr = true_positive_rate,\n",
        "        tnr = true_negative_rate\n",
        "    )\n",
        "    print(message)\n",
        "    \n",
        "  if leave_log:\n",
        "    fake_data_fixed = G(z_fixed)\n",
        "    image_path = result_dir + '/epoch{}.png'.format(epoch)\n",
        "    square_plot(fake_data_fixed.view(25, 28, 28).cpu().data.numpy(), path=image_path)\n",
        "    generated_images.append(image_path)\n",
        "    \n",
        "  if leave_log:\n",
        "    train_hist['D_losses'].append(torch.mean(torch.FloatTensor(D_losses)))\n",
        "    train_hist['G_losses'].append(torch.mean(torch.FloatTensor(G_losses)))\n",
        "\n",
        "torch.save(G.state_dict(), \"gan_generator.pkl\")  \n",
        "torch.save(D.state_dict(), \"gan_discriminator.pkl\")\n",
        "with open('gan_train_history.pkl', 'wb') as f:\n",
        "  pickle.dump(train_hist, f)\n",
        "\n",
        "generated_image_array = [imageio.imread(generated_image) for generated_image in generated_images]\n",
        "imageio.mimsave(result_dir + '/GAN_generation.gif', generated_image_array, fps=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0   D Loss: 1.35443  G Loss: 0.702965 True Positive Rate: 68.3% True Negative Rate: 93.3%\n",
            "Epoch: 1   D Loss: 1.35443  G Loss: 0.702967 True Positive Rate: 68.3% True Negative Rate: 91.7%\n",
            "Epoch: 2   D Loss: 1.35451  G Loss: 0.703019 True Positive Rate: 80.0% True Negative Rate: 93.3%\n",
            "Epoch: 3   D Loss: 1.35431  G Loss: 0.702968 True Positive Rate: 63.3% True Negative Rate: 91.7%\n",
            "Epoch: 4   D Loss: 1.35452  G Loss: 0.702903 True Positive Rate: 81.7% True Negative Rate: 91.7%\n",
            "Epoch: 5   D Loss: 1.35418  G Loss: 0.702937 True Positive Rate: 68.3% True Negative Rate: 98.3%\n",
            "Epoch: 6   D Loss: 1.35437  G Loss: 0.702901 True Positive Rate: 60.0% True Negative Rate: 91.7%\n",
            "Epoch: 7   D Loss: 1.35423  G Loss: 0.702936 True Positive Rate: 71.7% True Negative Rate: 93.3%\n",
            "Epoch: 8   D Loss: 1.35427  G Loss: 0.702915 True Positive Rate: 60.0% True Negative Rate: 90.0%\n",
            "Epoch: 9   D Loss: 1.35461  G Loss: 0.702893 True Positive Rate: 61.7% True Negative Rate: 86.7%\n",
            "Epoch: 10  D Loss: 1.35415  G Loss: 0.702979 True Positive Rate: 61.7% True Negative Rate: 88.3%\n",
            "Epoch: 11  D Loss: 1.35415  G Loss: 0.70293  True Positive Rate: 71.7% True Negative Rate: 95.0%\n",
            "Epoch: 12  D Loss: 1.35437  G Loss: 0.702981 True Positive Rate: 70.0% True Negative Rate: 93.3%\n",
            "Epoch: 13  D Loss: 1.35456  G Loss: 0.702976 True Positive Rate: 73.3% True Negative Rate: 93.3%\n",
            "Epoch: 14  D Loss: 1.35434  G Loss: 0.702919 True Positive Rate: 60.0% True Negative Rate: 96.7%\n",
            "Epoch: 15  D Loss: 1.35433  G Loss: 0.702905 True Positive Rate: 75.0% True Negative Rate: 86.7%\n",
            "Epoch: 16  D Loss: 1.35464  G Loss: 0.702927 True Positive Rate: 63.3% True Negative Rate: 88.3%\n",
            "Epoch: 17  D Loss: 1.35424  G Loss: 0.702943 True Positive Rate: 73.3% True Negative Rate: 93.3%\n",
            "Epoch: 18  D Loss: 1.35482  G Loss: 0.702962 True Positive Rate: 66.7% True Negative Rate: 90.0%\n",
            "Epoch: 19  D Loss: 1.35443  G Loss: 0.702918 True Positive Rate: 75.0% True Negative Rate: 91.7%\n",
            "Epoch: 20  D Loss: 1.35419  G Loss: 0.702933 True Positive Rate: 70.0% True Negative Rate: 88.3%\n",
            "Epoch: 21  D Loss: 1.35429  G Loss: 0.702924 True Positive Rate: 78.3% True Negative Rate: 88.3%\n",
            "Epoch: 22  D Loss: 1.35417  G Loss: 0.702917 True Positive Rate: 65.0% True Negative Rate: 93.3%\n",
            "Epoch: 23  D Loss: 1.35454  G Loss: 0.702945 True Positive Rate: 71.7% True Negative Rate: 95.0%\n",
            "Epoch: 24  D Loss: 1.35417  G Loss: 0.702981 True Positive Rate: 71.7% True Negative Rate: 93.3%\n",
            "Epoch: 25  D Loss: 1.35436  G Loss: 0.702959 True Positive Rate: 58.3% True Negative Rate: 86.7%\n",
            "Epoch: 26  D Loss: 1.35411  G Loss: 0.702914 True Positive Rate: 70.0% True Negative Rate: 90.0%\n",
            "Epoch: 27  D Loss: 1.3541   G Loss: 0.702942 True Positive Rate: 70.0% True Negative Rate: 91.7%\n",
            "Epoch: 28  D Loss: 1.35488  G Loss: 0.702935 True Positive Rate: 66.7% True Negative Rate: 83.3%\n",
            "Epoch: 29  D Loss: 1.35437  G Loss: 0.702917 True Positive Rate: 71.7% True Negative Rate: 91.7%\n",
            "Epoch: 30  D Loss: 1.35437  G Loss: 0.702942 True Positive Rate: 63.3% True Negative Rate: 96.7%\n",
            "Epoch: 31  D Loss: 1.35403  G Loss: 0.702915 True Positive Rate: 73.3% True Negative Rate: 96.7%\n",
            "Epoch: 32  D Loss: 1.35449  G Loss: 0.702982 True Positive Rate: 58.3% True Negative Rate: 90.0%\n",
            "Epoch: 33  D Loss: 1.35421  G Loss: 0.702936 True Positive Rate: 66.7% True Negative Rate: 91.7%\n",
            "Epoch: 34  D Loss: 1.35448  G Loss: 0.702943 True Positive Rate: 61.7% True Negative Rate: 90.0%\n",
            "Epoch: 35  D Loss: 1.35444  G Loss: 0.702976 True Positive Rate: 75.0% True Negative Rate: 88.3%\n",
            "Epoch: 36  D Loss: 1.35436  G Loss: 0.702942 True Positive Rate: 78.3% True Negative Rate: 96.7%\n",
            "Epoch: 37  D Loss: 1.35468  G Loss: 0.702932 True Positive Rate: 66.7% True Negative Rate: 93.3%\n",
            "Epoch: 38  D Loss: 1.35426  G Loss: 0.702905 True Positive Rate: 80.0% True Negative Rate: 95.0%\n",
            "Epoch: 39  D Loss: 1.35484  G Loss: 0.702949 True Positive Rate: 61.7% True Negative Rate: 95.0%\n",
            "Epoch: 40  D Loss: 1.35409  G Loss: 0.702939 True Positive Rate: 66.7% True Negative Rate: 85.0%\n",
            "Epoch: 41  D Loss: 1.35422  G Loss: 0.702887 True Positive Rate: 70.0% True Negative Rate: 95.0%\n",
            "Epoch: 42  D Loss: 1.35454  G Loss: 0.702937 True Positive Rate: 66.7% True Negative Rate: 90.0%\n",
            "Epoch: 43  D Loss: 1.35409  G Loss: 0.702933 True Positive Rate: 78.3% True Negative Rate: 88.3%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-813ce9eead39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# 진짜 이미지를 구분자에 넣음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mD_result_from_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m# 구분자 출력값이 정답지인 1에서 멀수록 loss가 높아짐\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mD_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_result_from_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-9ad563bab140>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR1YxtSkaVTj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}